[[决策树]]
# 1.基本概念
规则(rule): 机器学习中"规则"通常是语义明确 ,能描述数据分布所隐含的客观规律或领域概念, 可写成"若......则......"形式的**逻辑规则**.

规则学习(rule learning): 从训练数据中学习出一组能用于对未见示例进行判别的规则.
*(所有预测模型广义上都可以算一个/一组"规则",规则学习这里实际上是省略了"逻辑"的狭义"规则")*

形式化来看,一条规则形如:$$\oplus \leftarrow \mathbf f_1 \land \mathbf f_2 \land \cdots \land \mathbf f_L$$
$\leftarrow$:逻辑蕴含符号
右边部分:规则体(body),表示该条规则的前提.
左边部分:规则头(head) ,表示该条规则的结果.

规则体:由逻辑文字(literal) $\mathbf f_k$ 组成的合取式(conjunction),合取符号$\land$表示"并且".每个文字 $\mathbf f_k$ 都是对示例属性进行检验的布尔表达式.     $L$ : 规则的长度, 是规则体中逻辑文字的个数
规则头的$\oplus$ 同样是逻辑文字,一般用来表示规则所判定的目标类别或概念.
*(数理逻辑中,"文字"专指原子公式(atom)及其否定)*

规则学习可解释性好,便于引入领域知识,抽象描述能力在解决复杂问题时很有用.

假定我们从西瓜数据集上学得规则集合$\mathcal R$:
	规则1:$好瓜\leftarrow (根蒂=蜷缩)\land(脐部=凹陷);$
	规则2:$\lnot 好瓜\leftarrow (纹理=模糊);$
规则1长度为2,通过判断两个逻辑文字的赋值(valuation)来对示例进行判别.
符合该规则的样本称为被该规则 **"覆盖"**(cover).    *注意:未被规则1覆盖不一定不是好瓜*

规则集合中的每条规则可被看作一个子模型,规则模型是这些子模型的一个集成.[[集成学习]]
当一个示例被判别结果不同的多条规则覆盖时,称发生了 **"冲突"**(conflict).

**冲突消解(conflict resolution)**:解决冲突的办法
常用
1. 投票法
2. 排序法: 在规则集合上定义一个顺序,冲突时使用最靠前的规则;相应的规则学习的过程称为"带序规则学习"或"优先级学习".
3. 元规则法: 根据领域知识事先制定一些 **"元规则(meta-rule)"**,即规则的规则(eg:发生冲突时使用长度最小的规则)

此外,学得的规则集合可能不能覆盖所有的未见示例,so,制定 **"默认规则"(default rule)**.
eg:对上面的$\mathcal R$,未被上述两条规则覆盖的都是坏瓜

从形式语言表达能力而言,规则可分为两类
1. **命题规则**(propositional rule)
   由 **原子命题**(propositional atom)和逻辑连接词构成的简单陈述句.
   eg:"根蒂=凹陷"就是一个原子命题,规则集$\mathcal R$就是一个命题规则集.
2. **一阶规则**(first-order rule) 
   基本成分:能描述事物的属性或关系的 **"原子公式"**(atomic formula).
   会用到谓词(predicate),函数,量词(quantifier).<br><br>一阶规则能表达复杂的关系,因此也被称为"关系型规则"(relational rule).
命题规则集$\mathcal R$可改写为一阶规则集$\mathcal R'$:
	规则1:$好瓜(X)\leftarrow 根蒂(X,蜷缩)\land脐部(X,凹陷);$
	规则2:$\lnot 好瓜(X)\leftarrow 纹理(X,模糊);$
显然,命题规则是一阶规则的特例

# 2.序贯覆盖
**规则学习的目标**: 产生一个能覆盖尽可能多的样例的规则集.

so,最简单的:"**序贯覆盖**(sequential covering)",即逐条归纳
>[!tldr]
>在训练集上每学到一条规则,就将该规则覆盖到的训练样例去除.
>以剩下的样例组成的新训练集重复

由于每次只处理一部分数据,因此也被称为"分治"(separate-and-conquer)策略

以命题规则为例,序贯覆盖法的关键: 如何从训练集中学出单条规则.
对学习目标$\oplus$,产生一条规则就是寻找最优的一组逻辑文字来构成规则体,这是一个*搜索问题*.

给定正例集合和反例集合,学习任务是基于候选文字集合$\mathcal F=\{\mathbf f_k\}$来生成最优规则$\mathbf r$.命题规则学习中,候选文字是形如"$R(属性_i,属性值_{i,j})$"的布尔表达式.$(eg: \mathcal F=\{色泽=青绿?,色泽=乌黑?,...,\})$.

最简单的做法,穷举所有组合,找到最优.[[序贯覆盖--穷举 在西瓜数据集上的示例]]

现实中:
1. "自顶向下":从比较一般的规则开始,逐渐添加新文字以缩小规则覆盖范围,直到达到预定<br>亦称"生成-测试",是规则逐渐"特化"的过程.<br>*如不含任何属性的空规则*<br>注:与穷举不同,自顶向下寻找的是每一步的局部最优<br>
2. "自底向上":从比较特殊的规则开始,逐渐删除文字以扩大规则覆盖范围,直到满足条件.<br>亦称"数据驱动"法,是规则"泛化"的过程.<br>*如直接以某样例的属性取值形成规则,则该规则只覆盖此样例*

| 策略   | 特点                     | 常用场景                |
| ---- | ---------------------- | ------------------- |
| 自顶向下 | 易于产生泛化性能较好的规则,对噪声的鲁棒性强 | 命题规则学习              |
| 自底向上 | 更适合训练样本较少的情形,对噪声的鲁棒性差  | 一阶规则学习这类假设空间非常复杂的任务 |
[[自顶向下在西瓜数据集上的示例]]
规则生成过程中涉及一个评估规则优劣的标准.
上面的例子使用的标准是:先考虑规则准确率,准确率相同时考虑覆盖样例数,再相同时考虑属性次序. 现实中可根据具体任务设计不同的标准.

此外,上例中每次仅考虑一个"最优",易陷入局部最优.通常采用温和一点的做法
比如"**集数搜索**"(beam search)
 每轮保留最优的b个逻辑文字,在下一轮中均用于构建候选集,(假设一共有k个候选文字,则下一轮中有b\*k个候选集),然后再选择b个最优的用于下一轮.

序贯覆盖法简单有效,几乎所有的规则学习算法都以它为基本框架.
它能方便的**推广到多分类**问题上,只需将每类分别处理:   学习关于第c类的规则时,将其余所有类别都当作反例.

# 3.剪枝优化
[[决策树--剪枝]]    [[2.4统计显著性检验]]

规则生成本质上是一个贪心搜索过程,需有一定的机制来缓解过拟合风险.
常见: 剪枝(pruning).与决策树类似
1. 预剪枝:规则生长过程中
2. 后剪枝:规则长好后,基于某种性能度量来评估
剪枝还可借助统计显著性检验.
## 3.1预剪枝,以CN2为例

借助统计显著性检验的方法.
预剪枝时,假设用规则集进行预测必须显著优于直接基于训练样例集后验概率分布进行预测.

CN2使用了似然率统计量(Likelihood Ratio Statistics,LRS)
令$m_+,m_-$分别表示训练样例集中的正,反例数目,$\hat m_+,\hat m_-$分别表示规则(集)覆盖的正,反例数目.则$$
LRS = 2 \cdot \left( \hat{m}_+ \log_2 \frac{\left( \frac{\hat{m}_+}{\hat{m}_+ + \hat{m}_-} \right)}{\left( \frac{m_+}{m_+ + m_-} \right)} + \hat{m}_- \log_2 \frac{\left( \frac{\hat{m}_-}{\hat{m}_+ + \hat{m}_-} \right)}{\left( \frac{m_-}{m_+ + m_-} \right)} \right)
$$
这实际上是一种信息量指标,衡量了规则(集)覆盖样例的分布与训练集经验分布的差别:
LRS越大,说明采用规则(集)进行预测与直接使用训练集正,反例比率进行猜测的差别越大.

>[!note]
>也可以理解为 $\frac{\hat{m}_+}{\hat{m}_+ + \hat{m}_-}$ 和前面乘的相应的 $\hat m_+$ 刻画了规则(集)覆盖的样例的纯净程度

在数据量比较大的现实任务中,通常设置为在LRS很大(eg:0.99)时才停止规则(集)生长

## 3.2后剪枝
### REP
后剪枝常用策略:"减错剪枝"(Reduced Error Pruning,REP)

将样例分为训练集和验证集,从训练集上学得 $\mathcal R$ 后进行多轮剪枝,每一轮穷举所有可能的剪枝操作.
然后用验证集进行评估,保留效果最好的.
重复执行直到性能不在提升.

复杂度为$O(m^4),m$为训练样例数目
### IREP(Incremental REP)
复杂度降为$O(m \log^2 m)$.

在生成每条规则前,将样例划分为训练集和验证集.在训练集上生成一条规则$\mathbf r$,==立刻==在验证集上对其进行REP剪枝,得到规则 $\mathbf r'$ ,将 $\mathbf r'$ 覆盖的样例去除.
重复.

与REP相比,时针对单条规则而非整个规则集,因此高效.

### RIPPER
Repeated Incremental Pruning to Produce Error Reduction
将剪枝机制与其他后处理手段结合.

流程:
1. 先用 IREP* 剪枝机制生成规则集$\mathcal R$ .
    - IREP* 是IREP的改进,以$\frac{\hat m_+ +(m_- -\hat m_-)}{m_+ +m_-}$取代了IREP使用的准确率作为规则性能度量的指标,就是说不用划分验证集来检验泛化性能,降低复杂度. 
    - 剪枝则通过删除尾部的多个文字
2. 在学习最后一条规则时划分训练集和验证集,进行一次IREP    ?
3. 对得到的$\mathcal R$中的每条规则$\mathbf r_i$ ,产生两条变体:
	- $\mathbf r'_i$ :基于$\mathbf r_i$覆盖的样例,用 IREP* 重新生成一条规则$\mathbf r'_i$,该规则称为替换规则(replacement rule)
	- $\mathbf r''_i$ :对$\mathbf r_i$增加文字进行特化,然后再用 IREP* 剪枝生成一条规则$\mathbf r''_i$,该规则称为修定规则(revised rule)
4. 接下来,把$\mathbf r'_i \;, \mathbf r''_i$分别与$\mathcal R$中除$\mathbf r_i$之外的规则放在一起,组成规则集$\mathcal R' \;,\mathcal R''$,将他们与$\mathcal R$一起比较,选择最优的保留下来

关于判断优劣, 有一个MDL准则,综合评价了规则**长度**和**准确度**.

**1,2为剪枝; 3,4为后处理**
==后处理通过全局的考虑来缓解贪心算法的局部性==

# 4.一阶规则学习
命题规则学习难以处理对象之间的关系.
eg: 有时候我们难以判断什么样算是"色泽青绿",什么样算"敲声沉闷",而是比较A比B绿一些,且A声音更沉闷,所以A是好瓜.
然而,这已经超出了命题逻辑的表达能力,需用一阶逻辑表示,并且用一阶规则学习.

----
我们需要将原本的数据集转化为"关系数据集":

对西瓜数据,不妨定义:
色泽深度: 乌黑>青绿>浅白
根蒂蜷度:蜷缩>稍蜷>硬挺
......
可得西瓜数据5.0:![[西瓜数据5.0.png]]
这样的数据直接描述了样例间的关系,称为"关系数据"(relational data).
其中,由原样本属性转化而来的"色泽更深""根蒂更蜷"等原子公式称为"**背景知识**".
而由样本类别转化而来的关于"更好""$\lnot$更好"的原子公式称为**关系数据样例**(examples)

>[!note]
>理论上,如果有m个样本,那么每个样本都要和(m-1)个去比较,最后一个属性下面从m个值变成了m(m-1)个值. **组合爆炸**
>
>但是实际中,首先,比较是单向的,有了 "色泽更深(2,1)" 就不会有 "色泽更浅(1,2)";其次,相同属性值比不了;并且根据实际情况,我们可以不列出所有的关系,而是选择抽样.


从西瓜数据集5.0可以学出这样的一阶规则:$$(\forall X,\forall Y)(更好(X,Y)\leftarrow 根蒂更蜷(X,Y)\land 脐部更凹(X,Y))$$
个体对象"瓜1","瓜2"被逻辑变量"X","Y"替换
通常一阶规则中所有出现的变量都被全称量词限定,所以不影响的情况下可以省略量词.

若允许目标谓词作为候选文字加入规则体, 一阶规则可以表达递归:$$更好(X,Y)\leftarrow更好(X,Z)\land更好(Z,Y)$$

----
一阶规则学习能很容易地引入领域知识
而在命题规则学习乃至一般的统计学习中,引入领域知识通常有两种做法:
- 在现有属性的基础上,基于领域知识构造出新属性.
- 基于领域知识设计某种函数机制(eg:正则化)来对假设空间进行约束
这两种方法都有一定局限
----
## FOIL(First-Order Inductive Learner)
一阶规则学习算法,遵循序贯覆盖框架且采用自顶向下的规则归纳策略.
