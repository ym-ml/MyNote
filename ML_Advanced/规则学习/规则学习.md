[[决策树]]
# 1.基本概念
规则(rule): 机器学习中"规则"通常是语义明确 ,能描述数据分布所隐含的客观规律或领域概念, 可写成"若......则......"形式的**逻辑规则**.

规则学习(rule learning): 从训练数据中学习出一组能用于对未见示例进行判别的规则.
*(所有预测模型广义上都可以算一个/一组"规则",规则学习这里实际上是省略了"逻辑"的狭义"规则")*

形式化来看,一条规则形如:$$\oplus \leftarrow \mathbf f_1 \land \mathbf f_2 \land \cdots \land \mathbf f_L$$
$\leftarrow$:逻辑蕴含符号
右边部分:规则体(body),表示该条规则的前提.
左边部分:规则头(head) ,表示该条规则的结果.

规则体:由逻辑文字(literal) $\mathbf f_k$ 组成的合取式(conjunction),合取符号$\land$表示"并且".每个文字 $\mathbf f_k$ 都是对示例属性进行检验的布尔表达式.     $L$ : 规则的长度, 是规则体中逻辑文字的个数
规则头的$\oplus$ 同样是逻辑文字,一般用来表示规则所判定的目标类别或概念.
*(数理逻辑中,"文字"专指原子公式(atom)及其否定)*

规则学习可解释性好,便于引入领域知识,抽象描述能力在解决复杂问题时很有用.

假定我们从西瓜数据集上学得规则集合$\mathcal R$:
	规则1:$好瓜\leftarrow (根蒂=蜷缩)\land(脐部=凹陷);$
	规则2:$\lnot 好瓜\leftarrow (纹理=模糊);$
规则1长度为2,通过判断两个逻辑文字的赋值(valuation)来对示例进行判别.
符合该规则的样本称为被该规则 **"覆盖"**(cover).    *注意:未被规则1覆盖不一定不是好瓜*

规则集合中的每条规则可被看作一个子模型,规则模型是这些子模型的一个集成.[[集成学习]]
当一个示例被判别结果不同的多条规则覆盖时,称发生了 **"冲突"**(conflict).

**冲突消解(conflict resolution)**:解决冲突的办法
常用
1. 投票法
2. 排序法: 在规则集合上定义一个顺序,冲突时使用最靠前的规则;相应的规则学习的过程称为"带序规则学习"或"优先级学习".
3. 元规则法: 根据领域知识事先制定一些 **"元规则(meta-rule)"**,即规则的规则(eg:发生冲突时使用长度最小的规则)

此外,学得的规则集合可能不能覆盖所有的未见示例,so,制定 **"默认规则"(default rule)**.
eg:对上面的$\mathcal R$,未被上述两条规则覆盖的都是坏瓜

从形式语言表达能力而言,规则可分为两类
1. **命题规则**(propositional rule)
   由 **原子命题**(propositional atom)和逻辑连接词构成的简单陈述句.
   eg:"根蒂=凹陷"就是一个原子命题,规则集$\mathcal R$就是一个命题规则集.
2. **一阶规则**(first-order rule) 
   基本成分:能描述事物的属性或关系的 **"原子公式"**(atomic formula).
   会用到谓词(predicate),函数,量词(quantifier).<br><br>一阶规则能表达复杂的关系,因此也被称为"关系型规则"(relational rule).
命题规则集$\mathcal R$可改写为一阶规则集$\mathcal R'$:
	规则1:$好瓜(X)\leftarrow 根蒂(X,蜷缩)\land脐部(X,凹陷);$
	规则2:$\lnot 好瓜(X)\leftarrow 纹理(X,模糊);$
显然,命题规则是一阶规则的特例

# 2.序贯覆盖
**规则学习的目标**: 产生一个能覆盖尽可能多的样例的规则集.

so,最简单的:"**序贯覆盖**(sequential covering)",即逐条归纳
>[!tldr]
>在训练集上每学到一条规则,就将该规则覆盖到的训练样例去除.
>以剩下的样例组成的新训练集重复

由于每次只处理一部分数据,因此也被称为"分治"(separate-and-conquer)策略

以命题规则为例,序贯覆盖法的关键: 如何从训练集中学出单条规则.
对学习目标$\oplus$,产生一条规则就是寻找最优的一组逻辑文字来构成规则体,这是一个*搜索问题*.

给定正例集合和反例集合,学习任务是基于候选文字集合$\mathcal F=\{\mathbf f_k\}$来生成最优规则$\mathbf r$.命题规则学习中,候选文字是形如"$R(属性_i,属性值_{i,j})$"的布尔表达式.$(eg: \mathcal F=\{色泽=青绿?,色泽=乌黑?,...,\})$.

最简单的做法,穷举所有组合,找到最优.[[序贯覆盖--穷举 在西瓜数据集上的示例]]

现实中:
1. "自顶向下":从比较一般的规则开始,逐渐添加新文字以缩小规则覆盖范围,直到达到预定<br>亦称"生成-测试",是规则逐渐"特化"的过程.<br>*如不含任何属性的空规则*<br>注:与穷举不同,自顶向下寻找的是每一步的局部最优<br>
2. "自底向上":从比较特殊的规则开始,逐渐删除文字以扩大规则覆盖范围,直到满足条件.<br>亦称"数据驱动"法,是规则"泛化"的过程.<br>*如直接以某样例的属性取值形成规则,则该规则只覆盖此样例*

| 策略   | 特点                     | 常用场景                |
| ---- | ---------------------- | ------------------- |
| 自顶向下 | 易于产生泛化性能较好的规则,对噪声的鲁棒性强 | 命题规则学习              |
| 自底向上 | 更适合训练样本较少的情形,对噪声的鲁棒性差  | 一阶规则学习这类假设空间非常复杂的任务 |

[[自顶向下在西瓜数据集上的示例]]
规则生成过程中涉及一个评估规则优劣的标准.
上面的例子使用的标准是:先考虑规则准确率,准确率相同时考虑覆盖样例数,再相同时考虑属性次序. 现实中可根据具体任务设计不同的标准.

此外,上例中每次仅考虑一个"最优",易陷入局部最优.通常采用温和一点的做法
比如"**集数搜索**"(beam search)
 每轮保留最优的b个逻辑文字,在下一轮中均用于构建候选集,(假设一共有k个候选文字,则下一轮中有b\*k个候选集),然后再选择b个最优的用于下一轮.

序贯覆盖法简单有效,几乎所有的规则学习算法都以它为基本框架.
它能方便的**推广到多分类**问题上,只需将每类分别处理:   学习关于第c类的规则时,将其余所有类别都当作反例.

# 3.剪枝优化
[[决策树--剪枝]]    [[2.4统计显著性检验]]

规则生成本质上是一个贪心搜索过程,需有一定的机制来缓解过拟合风险.
常见: 剪枝(pruning).与决策树类似
1. 预剪枝:规则生长过程中
2. 后剪枝:规则长好后,基于某种性能度量来评估
剪枝还可借助统计显著性检验.
## 3.1预剪枝,以CN2为例

借助统计显著性检验的方法.
预剪枝时,假设用规则集进行预测必须显著优于直接基于训练样例集后验概率分布进行预测.

CN2使用了似然率统计量(Likelihood Ratio Statistics,LRS)
令$m_+,m_-$分别表示训练样例集中的正,反例数目,$\hat m_+,\hat m_-$分别表示规则(集)覆盖的正,反例数目.则$$
LRS = 2 \cdot \left( \hat{m}_+ \log_2 \frac{\left( \frac{\hat{m}_+}{\hat{m}_+ + \hat{m}_-} \right)}{\left( \frac{m_+}{m_+ + m_-} \right)} + \hat{m}_- \log_2 \frac{\left( \frac{\hat{m}_-}{\hat{m}_+ + \hat{m}_-} \right)}{\left( \frac{m_-}{m_+ + m_-} \right)} \right)
$$
这实际上是一种信息量指标,衡量了规则(集)覆盖样例的分布与训练集经验分布的差别:
LRS越大,说明采用规则(集)进行预测与直接使用训练集正,反例比率进行猜测的差别越大.

>[!note]
>也可以理解为 $\frac{\hat{m}_+}{\hat{m}_+ + \hat{m}_-}$ 和前面乘的相应的 $\hat m_+$ 刻画了规则(集)覆盖的样例的纯净程度

在数据量比较大的现实任务中,通常设置为在LRS很大(eg:0.99)时才停止规则(集)生长

## 3.2后剪枝
### REP
后剪枝常用策略:"减错剪枝"(Reduced Error Pruning,REP)

将样例分为训练集和验证集,从训练集上学得 $\mathcal R$ 后进行多轮剪枝,每一轮穷举所有可能的剪枝操作.
然后用验证集进行评估,保留效果最好的.
重复执行直到性能不在提升.

复杂度为$O(m^4),m$为训练样例数目
### IREP(Incremental REP)
复杂度降为$O(m \log^2 m)$.

在生成每条规则前,将样例划分为训练集和验证集.在训练集上生成一条规则$\mathbf r$,==立刻==在验证集上对其进行REP剪枝,得到规则 $\mathbf r'$ ,将 $\mathbf r'$ 覆盖的样例去除.
重复.

与REP相比,时针对单条规则而非整个规则集,因此高效.

### RIPPER
Repeated Incremental Pruning to Produce Error Reduction
将剪枝机制与其他后处理手段结合.

流程:
1. 先用 IREP* 剪枝机制生成规则集$\mathcal R$ .
    - IREP* 是IREP的改进,以$\frac{\hat m_+ +(m_- -\hat m_-)}{m_+ +m_-}$取代了IREP使用的准确率作为规则性能度量的指标,就是说不用划分验证集来检验泛化性能,降低复杂度. 
    - 剪枝则通过删除尾部的多个文字
2. 在学习最后一条规则时划分训练集和验证集,进行一次IREP    ?
3. 对得到的$\mathcal R$中的每条规则$\mathbf r_i$ ,产生两条变体:
	- $\mathbf r'_i$ :基于$\mathbf r_i$覆盖的样例,用 IREP* 重新生成一条规则$\mathbf r'_i$,该规则称为替换规则(replacement rule)
	- $\mathbf r''_i$ :对$\mathbf r_i$增加文字进行特化,然后再用 IREP* 剪枝生成一条规则$\mathbf r''_i$,该规则称为修定规则(revised rule)
4. 接下来,把$\mathbf r'_i \;, \mathbf r''_i$分别与$\mathcal R$中除$\mathbf r_i$之外的规则放在一起,组成规则集$\mathcal R' \;,\mathcal R''$,将他们与$\mathcal R$一起比较,选择最优的保留下来

关于判断优劣, 有一个MDL准则,综合评价了规则**长度**和**准确度**.

**1,2为剪枝; 3,4为后处理**
==后处理通过全局的考虑来缓解贪心算法的局部性==

# 4.一阶规则学习
命题规则学习难以处理对象之间的关系.
eg: 有时候我们难以判断什么样算是"色泽青绿",什么样算"敲声沉闷",而是比较A比B绿一些,且A声音更沉闷,所以A是好瓜.
然而,这已经超出了命题逻辑的表达能力,需用一阶逻辑表示,并且用一阶规则学习.

----
我们需要将原本的数据集转化为"关系数据集":

对西瓜数据,不妨定义:
色泽深度: 乌黑>青绿>浅白
根蒂蜷度:蜷缩>稍蜷>硬挺
......
可得西瓜数据5.0:![[西瓜数据5.0.png]]
这样的数据直接描述了样例间的关系,称为"关系数据"(relational data).
其中,由原样本属性转化而来的"色泽更深""根蒂更蜷"等原子公式称为"**背景知识**".
而由样本类别转化而来的关于"更好""$\lnot$更好"的原子公式称为**关系数据样例**(examples)

>[!note]
>理论上,如果有m个样本,那么每个样本都要和(m-1)个去比较,最后一个属性下面从m个值变成了m(m-1)个值. **组合爆炸**
>
>但是实际中,首先,比较是单向的,有了 "色泽更深(2,1)" 就不会有 "色泽更浅(1,2)";其次,相同属性值比不了;并且根据实际情况,我们可以不列出所有的关系,而是选择抽样.


从西瓜数据集5.0可以学出这样的一阶规则:$$(\forall X,\forall Y)(更好(X,Y)\leftarrow 根蒂更蜷(X,Y)\land 脐部更凹(X,Y))$$
个体对象"瓜1","瓜2"被逻辑变量"X","Y"替换
通常一阶规则中所有出现的变量都被全称量词限定,所以不影响的情况下可以省略量词.

若允许目标谓词作为候选文字加入规则体, 一阶规则可以表达递归:$$更好(X,Y)\leftarrow更好(X,Z)\land更好(Z,Y)$$

----
一阶规则学习能很容易地引入领域知识
而在命题规则学习乃至一般的统计学习中,引入领域知识通常有两种做法:
- 在现有属性的基础上,基于领域知识构造出新属性.
- 基于领域知识设计某种函数机制(eg:正则化)来对假设空间进行约束
这两种方法都有一定局限
----
## FOIL(First-Order Inductive Learner)

一阶规则学习算法,遵循序贯覆盖框架且采用自顶向下的规则归纳策略.
[[FOIL.excalidraw]]

FOIL可大致看作**命题规则学习**和**归纳逻辑程序设计**之间的**过渡**

# 5.归纳逻辑程序设计(ILP)
(Inductive Logic Programming ,ILP)
在一阶规则学习中引入了函数和逻辑表达式嵌套
- 一方面,增强了机器学习系统的表达能力
- 另一方面,ILP可看作用机器学习技术来解决基于背景知识的逻辑程序归纳,其学得的规则可被PROLOG等逻辑程序设计语言直接使用
However,计算上面临巨大挑战.给定一元谓词$P$和一元函数$f$
- 规则学习过程中可能的候选原子公式有无穷多个,$P(X),P(f(X))...$,自顶向下行不通
- FOIL增益也无法计算
- ......

现实任务中,ILP系统通常先自底向上生成一组规则,然后再结合最小一般泛化与逆归结做进一步的学习
## 5.1最小一般泛化

归纳逻辑程序设计采用**自底向上**的规则生成策略,
直接将一个或多个正例所对应的具体事实(grounded fact)作为初始规则,再对规则逐步进行泛化以增加其对样例的覆盖率.

泛化操作可以是将样例中的常量替换为逻辑变量,也可以是删除规则体中的某个文字

以西瓜数据集5.0为例,简便起见,暂且假定"更好(X,Y)"仅决定于(X,Y)取值相同的关系,正例"更好(1,10)"和"更好(1,15)"所对应的初始规则分别为:$$\begin{aligned}
更好(1,10)&\leftarrow 根蒂更蜷(1,10)\land 声音更沉(1,10)\\ &\land 脐部更凹(1,10)\land 触感更硬(1,10);\\
更好(1,15)&\leftarrow 根蒂更蜷(1,15)\land  脐部更凹(1,15)\land 触感更硬(1,15).\\
\end{aligned}$$
我们希望将这两条"特殊"规则泛化为"一般"的规则.

----
最基础的技术 **"最小一般泛化"**(Least General Generalization,LGG)

给定一阶公式$\mathbf r_1 和\mathbf r_2$.
1. LGG找出涉及相同谓词的文字
2. 对文字中的每一个位置的常量逐一进行考察
	- 两个文字中常量相同,则记为$LGG(t,t)=t$.
	- 不同,替换为变量$V$,记为$LGG(s,t)=V$.并且以后所有出现s,t的地方都换成V.
3. 忽略不含共同谓词的文字

对上例, 1,1不变; $10,15\rightarrow Y$
可得:$$\begin{aligned}
更好(1,V)&\leftarrow 根蒂更蜷(1,V)\land 声音更沉(1,10)\\ &\land 脐部更凹(1,V)\land 触感更硬(1,V);\\
更好(1,V)&\leftarrow 根蒂更蜷(1,V)\land  脐部更凹(1,V)\land 触感更硬(1,V).\\
\end{aligned}$$
忽略"声音更沉(1,10)",得到LGG为:$$更好(1,V)\leftarrow 根蒂更蜷(1,V)\land  脐部更凹(1,V)\land 触感更硬(1,V)\tag{5.1.1}$$
式(5.1.1)仅能判断瓜1是否比其他瓜好,为提升其泛化性能,使用别的初始规则,继续上述过程.
假设有一条关于瓜2的:$$\begin{aligned}
更好(2,10)&\leftarrow 颜色更深(2,10)\land 根蒂更蜷(2,10)\land 声音更沉(2,10)\\ &\land 脐部更凹(2,10)\land 触感更硬(2,10);\\
\end{aligned}\tag{5.1.2}$$
同理令$LGG(10,Y)\rightarrow Y_2$ ...
于是可得新规则:$$更好(X,Y_2)\leftarrow 根蒂更蜷(X,Y_2)\land  脐部更凹(X,Y_2)\land 触感更硬(X,Y_2)\tag{5.1.3}$$
容易证明, LGG 是能特化为 $\mathbf r_1 和 \mathbf r_2$ 的所有一阶公式中最特殊的一个:  不存在既能特化为$\mathbf r_1 和 \mathbf r_2$，也能泛化为它们的LGG 的一阶公式$\mathbf r'$.

----

实际上,LGG还能进行更为复杂的泛化操作,如使用"$\lnot$"符号

此外,初始规则选择时可加入领域知识.
最常用的是**RLGG**:  将样例 $e$ 的初始规则定义为 $e \leftarrow K$ ,其中$K$是背景知识中所有原子的合取.

在归纳逻辑程序设计中，获得LGG之后，可将其看作单条规则加入规则集,不断重复填充规则集. 最后再用前几节介绍的技术进一步优化 (eg: 对规则集进行后剪枝等)


## 5.2逆归结
>[!failure]
>涉及逻辑,推理对我过于抽象

归结原理的逆过程.
去发明新谓词,这些新谓词可能对应于样例属性和背景知识中不存在的新知识

# 6.阅读材料
1. 规则学习是"符号主义学习"(symbolism learning)的主要代表
2. 规则学习与决策树学习相比的优点:
   决策树试图将样本空间划分为不重叠的等价类, 而规则学习并不强求这一点，因此后者学得的模型能有更低的复杂度.
   *决策树的每个叶节点对应一个等价类*
3. RIPPER是命题规则学习技术的高峰,达到了比C4.5决策树即快又好的效果
4. 由于ILP学得的规则几乎能被PROLOG等逻辑程序解释器直接调用, ILP成为连接机器学习和专家工程的桥梁  
5. PROGOL(将逆归结改进为逆蕴含) 和 ALEPH是应用广泛的ILP系统.
6. 将**关系学习**与**统计学习**相结合,是机器学习发展的一大趋势.(已有概率归纳逻辑程序设计,关系贝叶斯网等)